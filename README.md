Sberbank Data Science Journey 2018: AutoML
==========================================

Материалы к соревнованию по автоматизированному машинному обучению [SDSJ 2018 AutoML](http://sdsj.sberbank.ai/).

## Описание задачи

SDSJ AutoML — соревнование по построению алгоритмов машинного обучения, выполняющих автоматически такие действия как предобработка данных, выбор семейства моделей, подбор гиперпараметров. 

## Формат набора данных

Данные передаются решению в формате [CSV](https://en.wikipedia.org/wiki/Comma-separated_values). В наборах данных присутствуют следующие колонки:

- `line_id` — идентификатор строки
- `target` — целевая переменная (только для обучающего набора), вещественное число для регрессии и 0/1 для классификации
- `<type>_<feature>` — признак одного из возможных типов (`type`):
    - `number` — числовой формат (может содержать количественную, категориальную или бинарную величину)
    - `string` — строковый формат
    - `datetime` — дата в формате `2010-01-01` или дата/время в формате `2010-01-01 10:10:10`
    - `id` — идентификатор (категориальная величина особой природы)


## Формат решения

В проверяющую систему необходимо отправить код алгоритма, запакованный в ZIP-архив. Решения запускаются в изолированном окружении при помощи [Docker](https://www.docker.com/what-docker), время и ресурсы для тестирования ограничены. В простом случае, участнику нет необходимости разбираться с технологией Docker.

В корне архива обязательно должен быть файл `metadata.json` следующего содержания:

```json
{
    "image": "sberbank/python",
    "entry_points": {
        "train_classification": "python train.py --mode classification --train-csv {train_csv} --model-dir {model_dir}",
        "train_regression": "python train.py --mode regression --train-csv {train_csv} --model-dir {model_dir}",
        "predict": "python predict.py --test-csv {test_csv} --prediction-csv {prediction_csv} --model-dir {model_dir}"
    }
}
```

Здесь `image` — поле с названием docker-образа, в котором будет запускаться решение, `entry_points` — команды, при помощи которых запускается решение (`train_*` — обучение модели в режиме классификации и регрессии, `predict` — построение предсказаний с использованием обученной модели). Для решения текущей директорией будет являться корень архива. 

В командах необходимо использовать шаблоны, в которые при запуске в тестирующей системе будут подставлены необходимые значения: 
- `{train_csv}`, `{test_csv}` — путь к CSV-файлу с обучающей или тестовой выборкой
- `{model_dir}` — путь к заранее созданной директории, в которую необходимо положить обученную модель для последующего использования
- `{prediction_csv}` — путь к файлу, в который необходимо записать предсказания

При запуске решения, в переменной окружения `TIME_LIMIT` указывается максимальное время (в секундах), которое разрешено работать алгоритму. 
Гарантируется, что алгоритму отдельно на обучение и предсказание дается не менее 300 секунд, однако для больших наборов данных этот лимит повышен. 

Для запуска решений можно использовать существующие окружения:

- `sberbank/python` — Python3 с установленным большим набором библиотек ([подробнее](images/sberbank-python))
- `gcc` - для запуска компилируемых C/C++ решений (подробнее здесь)
- `node` — для запуска JavaScript
- `openjdk` — для Java
- `mono` — для C#

Подойдет любой другой образ, доступный для загрузки из [DockerHub](http://dockerhub.com). При необходимости, Вы можете подготовить свой образ, добавить в него необходимое ПО и библиотеки (см. [инструкцию по созданию Docker-образов](https://docs.docker.com/engine/reference/builder/)); для использования его необходимо будет опубликовать на DockerHub.

## Ограничения

Контейнер с решением запускается в следующих условиях:

- решению доступны ресурсы
  - **12 Гб** оперативной памяти
  - 4 vCPU
- решение не имеет доступа к ресурсам интернета
- максимальный размер упакованного и распакованного архива с решением: **1 Гб**
- архив распаковывается в файловую систему, находящуюся в оперативной памяти (ramfs), доступную решению для записи
- остальное содержимое контейнера доступно только для чтения
- CSV с набором данных не превышает **3 Гб**


## Система оценки

1. Для каждой задачи (датасету) по тестовой части выборки считается метрика, специфичная для задачи (RMSE для регрессии, ROC-AUC для бинарной классификации).
2. Для каждой задачи (датасета) производится перевод значения метрик участников в общую шкалу по следующей схеме. За наилучшее по метрике решение (среди всех отправленных и успешно протестированных решений) даётся 1 балл, бейзлайн-решение оценивается в 0 баллов. Участники, находящиеся по метрике между наилучшим и бейзлайн-решениями получают пропорциональное количество баллов между 0 и 1. Решения по качество ниже бейзлайна оцениваются в 0 баллов. Если наилучшее решение и бейзлайн решения совпадают, то все участники получают 0 баллов. Если решение участника выдаёт на задаче ошибку или не проходит по временному ограничению, то оно получают за эту задачу 0 баллов.
3. Итоговый результат каждого участника считается как сумма результатов по каждой задачи после переда в общую шкалу. В общем лидерборде участники ранжируются по итоговому результату.


## Примеры запуска и примеры наборов данных

Публичный набор датасетов для локального тестирования решений: [sdsj2018_automl_check_datasets.zip](https://s3.eu-central-1.amazonaws.com/sdsj2018-automl/public/sdsj2018_automl_check_datasets.zip)

